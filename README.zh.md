# DB-GPT-Hub:åˆ©ç”¨LLMså®ç°Text-to-SQL

<div align="center">
  <p>
    <a href="https://github.com/eosphoros-ai/DB-GPT">
        <img alt="stars" src="https://img.shields.io/github/stars/eosphoros-ai/db-gpt-hub?style=social" />
    </a>
    <a href="https://github.com/eosphoros-ai/DB-GPT-Hub">
        <img alt="forks" src="https://img.shields.io/github/forks/eosphoros-ai/db-gpt-hub?style=social" />
    </a>
    <a href="https://opensource.org/licenses/MIT">
      <img alt="License: MIT" src="https://img.shields.io/badge/License-MIT-yellow.svg" />
    </a>
    <a href="https://github.com/eosphoros-ai/DB-GPT-Hub/releases">
      <img alt="Release Notes" src="https://img.shields.io/github/release/eosphoros-ai/DB-GPT-Hub" />
    </a>
    <a href="https://github.com/eosphoros-ai/DB-GPT-Hub/issues">
      <img alt="Open Issues" src="https://img.shields.io/github/issues-raw/eosphoros-ai/DB-GPT-Hub" />
    </a>
    <a href="https://discord.gg/7uQnPuveTY">
      <img alt="Discord" src="https://dcbadge.vercel.app/api/server/7uQnPuveTY?compact=true&style=flat" />
    </a>
  </p>


[**è‹±æ–‡**](README.md) | [**Discord**](https://discord.gg/7uQnPuveTY) | [**Wechat**](https://github.com/eosphoros-ai/DB-GPT/blob/main/README.zh.md#%E8%81%94%E7%B3%BB%E6%88%91%E4%BB%AC) | [**Huggingface**](https://huggingface.co/eosphoros) | [**Community**](https://github.com/eosphoros-ai/community)


[**Text2SQL**](README.zh.md) | [**Text2GQL**](src/dbgpt-hub-gql/README.zh.md) | [**Text2NLU**](src/dbgpt-hub-nlu/README.zh.md)
</div>


## ğŸ”¥ğŸ”¥ğŸ”¥ News
- æ”¯æŒ [Text2NLU](src/dbgpt-hub-nlu/README.zh.md)å¾®è°ƒ,æå‡è‡ªç„¶è¯­è¨€ç†è§£å‡†ç¡®ç‡ã€‚
- æ”¯æŒ [Text2GQL](src/dbgpt-hub-gql/README.zh.md)å¾®è°ƒ,å¯ä»¥é€šè¿‡è‡ªç„¶è¯­è¨€ç”Ÿæˆå›¾æŸ¥è¯¢è¯­å¥ã€‚

## Baseline
- æ›´æ–°æ—¥æœŸ: 2023/12/08
- è¯„ä»·æŒ‡æ ‡: execution accuracy (ex)
- è¯¦æƒ…å‚è€ƒ[docs/eval-llm-result.md](https://github.com/eosphoros-ai/DB-GPT-Hub/blob/main/docs/eval_llm_result.md)

<table style="text-align: center;">
  <tr>
    <th style="text-align: center;">Model</th>
    <th>Method</th>
    <th>Easy</th>
    <th>Medium</th>
    <th>Hard</th>
    <th>Extra</th>
    <th>All</th>
  </tr>
  <tr >
    <td></td>
    <td>base</td>
    <td>0</td>
    <td>0</td>
    <td>0</td>
    <td>0</td>
    <td>0</td>
  </tr>
  <tr>
    <td>Llama2-7B-Chat</td>
    <td>lora</td>
    <td>0.887</td>
    <td>0.641</td>
    <td>0.489</td>
    <td>0.331</td>
    <td>0.626</td>
  </tr>
  <tr>
    <td></td>
    <td>qlora</td>
    <td>0.847</td>
    <td>0.623</td>
    <td>0.466</td>
    <td>0.361</td>
    <td>0.608</td>
  </tr>
  <tr>
    <td></td>
    <td>base</td>
    <td>0</td>
    <td>0</td>
    <td>0</td>
    <td>0</td>
    <td>0</td>
  </tr>
  <tr>
    <td>Llama2-13B-Chat</td>
    <td>lora</td>
    <td>0.907</td>
    <td>0.729</td>
    <td>0.552</td>
    <td>0.343</td>
    <td>0.68</td>
  </tr>
  <tr>
    <td></td>
    <td>qlora</td>
    <td>0.911</td>
    <td>0.7</td>
    <td>0.552</td>
    <td>0.319</td>
    <td>0.664</td>
  </tr>
  <tr>
    <td></td>
    <td>base</td>
    <td>0.214</td>
    <td>0.177</td>
    <td>0.092</td>
    <td>0.036</td>
    <td>0.149</td>
  </tr>
  <tr>
  <td>CodeLlama-7B-Instruct</td>
    <td>lora</td>
    <td>0.923</td>
    <td>0.756</td>
    <td>0.586</td>
    <td>0.349</td>
    <td>0.702</td>
  </tr>
  <tr>
    <td></td>
    <td>qlora</td>
    <td>0.911</td>
    <td>0.751</td>
    <td>0.598</td>
    <td>0.331</td>
    <td>0.696</td>
  </tr>
  <tr>
    <td></td>
    <td>base</td>
    <td>0.698</td>
    <td>0.601</td>
    <td>0.408</td>
    <td>0.271</td>
    <td>0.539</td>
  </tr>
  <tr>
    <td>CodeLlama-13B-Instruct</td>
    <td>lora</td>
    <td>0.94</td>
    <td>0.789</td>
    <td>0.684</td>
    <td>0.404</td>
    <td>0.746</td>
  </tr>
  <tr>
    <td></td>
    <td>qlora</td>
    <td>0.94</td>
    <td>0.774</td>
    <td>0.626</td>
    <td>0.392</td>
    <td>0.727</td>
  </tr>
  <tr>
    <td></td>
    <td>base</td>
    <td>0.577</td>
    <td>0.352</td>
    <td>0.201</td>
    <td>0.066</td>
    <td>0.335</td>
  </tr>
  <tr>
    <td>Baichuan2-7B-Chat</td>
    <td>lora</td>
    <td>0.871</td>
    <td>0.63</td>
    <td>0.448</td>
    <td>0.295</td>
    <td>0.603</td>
  </tr>
  <tr>
  <td></td>
    <td>qlora</td>
    <td>0.891</td>
    <td>0.637</td>
    <td>0.489</td>
    <td>0.331</td>
    <td>0.624</td>
  </tr>
  <tr>
    <td></td>
    <td>base</td>
    <td>0.581</td>
    <td>0.413</td>
    <td>0.264</td>
    <td>0.187</td>
    <td>0.392</td>
  </tr>
    <tr>
    <td>Baichuan2-13B-Chat</td>
    <td>lora</td>
    <td>0.903</td>
    <td>0.702</td>
    <td>0.569</td>
    <td>0.392</td>
    <td>0.678</td>
    </tr>
  <tr>
  <td></td>
    <td>qlora</td>
    <td>0.895</td>
    <td>0.675</td>
    <td>0.58</td>
    <td>0.343</td>
    <td>0.659</td>
  </tr>
  <tr>
  <td></td>
  <td>base</td>
  <td>0.395</td>
  <td>0.256</td>
  <td>0.138</td>
  <td>0.042</td>
  <td>0.235</td>
  </tr>
<tr>
<td>Qwen-7B-Chat</td>
  <td>lora</td>
  <td>0.855</td>
  <td>0.688</td>
  <td>0.575</td>
  <td>0.331</td>
  <td>0.652</td>
  </tr>
  <tr>
    <td></td>
    <td>qlora</td>
    <td>0.911</td>
    <td>0.675</td>
    <td>0.575</td>
    <td>0.343</td>
    <td>0.662</td>
  </tr>
  <tr>
  <td></td>
  <td>base</td>
  <td>0.871</td>
  <td>0.632</td>
  <td>0.368</td>
  <td>0.181</td>
  <td>0.573</td>
  </tr>
  <tr>
    <td>Qwen-14B-Chat</td>
    <td>lora</td>
    <td>0.895</td>
    <td>0.702</td>
    <td>0.552</td>
    <td>0.331</td>
    <td>0.663</td>
  </tr>
  <tr>
    <td></td>
    <td>qlora</td>
    <td>0.919</td>
    <td>0.744</td>
    <td>0.598</td>
    <td>0.367</td>
  <td>0.701</td>
  </tr>
    <tr>
    <td></td>
    <td>base</td>
    <td>0</td>
    <td>0</td>
    <td>0</td>
    <td>0</td>
    <td>0</td>
  </tr>
  <tr>
    <td>ChatGLM3-6b</td>
    <td>lora</td>
    <td>0.855</td>
    <td>0.605</td>
    <td>0.477</td>
    <td>0.271</td>
    <td>0.59</td>
  </tr>
  <tr>
    <td></td>
    <td>qlora</td>
    <td>0.843</td>
    <td>0.603</td>
    <td>0.506</td>
    <td>0.211</td>
    <td>0.581</td>
  </tr>
</table>
 
## Contents
- [DB-GPT-Hub:åˆ©ç”¨LLMså®ç°Text-to-SQL](#db-gpt-hubåˆ©ç”¨llmså®ç°text-to-sql)
  - [Baseline](#baseline)
  - [Contents](#contents)
  - [ä¸€ã€ç®€ä»‹](#ä¸€ç®€ä»‹)
  - [äºŒã€Text-to-SQLå¾®è°ƒ](#äºŒtext-to-sqlå¾®è°ƒ)
    - [2.1ã€æ•°æ®é›†](#21æ•°æ®é›†)
    - [2.2ã€åŸºåº§æ¨¡å‹](#22åŸºåº§æ¨¡å‹)
  - [ä¸‰ã€ä½¿ç”¨æ–¹æ³•](#ä¸‰ä½¿ç”¨æ–¹æ³•)
    - [3.1ã€ç¯å¢ƒå‡†å¤‡](#31ç¯å¢ƒå‡†å¤‡)
    - [3.2ã€æ•°æ®å‡†å¤‡](#32æ•°æ®å‡†å¤‡)
    - [3.2 å¿«é€Ÿå¼€å§‹](#32-å¿«é€Ÿå¼€å§‹)
    - [3.3ã€æ¨¡å‹å¾®è°ƒ](#33æ¨¡å‹å¾®è°ƒ)
    - [3.4ã€æ¨¡å‹é¢„æµ‹](#34æ¨¡å‹é¢„æµ‹)
    - [3.5ã€æ¨¡å‹æƒé‡](#35æ¨¡å‹æƒé‡)
      - [3.5.1 æ¨¡å‹å’Œå¾®è°ƒæƒé‡åˆå¹¶](#351-æ¨¡å‹å’Œå¾®è°ƒæƒé‡åˆå¹¶)
    - [3.6ã€æ¨¡å‹è¯„ä¼°](#36æ¨¡å‹è¯„ä¼°)
  - [å››ã€å‘å±•è·¯çº¿](#å››å‘å±•è·¯çº¿)
  - [äº”ã€è´¡çŒ®](#äº”è´¡çŒ®)
  - [å…­ã€æ„Ÿè°¢](#å…­æ„Ÿè°¢)
  - [ä¸ƒã€å¼•ç”¨](#ä¸ƒå¼•ç”¨)
  - [å…«ã€Licence](#å…«licence)
  - [ä¹ã€æˆ‘ä»¬çš„è”ç³»æ–¹å¼](#ä¹æˆ‘ä»¬çš„è”ç³»æ–¹å¼)

## ä¸€ã€ç®€ä»‹

DB-GPT-Hubæ˜¯ä¸€ä¸ªåˆ©ç”¨LLMså®ç°Text-to-SQLè§£æçš„å®éªŒé¡¹ç›®ï¼Œä¸»è¦åŒ…å«æ•°æ®é›†æ”¶é›†ã€æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹é€‰æ‹©ä¸æ„å»ºå’Œå¾®è°ƒæƒé‡ç­‰æ­¥éª¤ï¼Œé€šè¿‡è¿™ä¸€ç³»åˆ—çš„å¤„ç†å¯ä»¥åœ¨æé«˜Text-to-SQLèƒ½åŠ›çš„åŒæ—¶é™ä½æ¨¡å‹è®­ç»ƒæˆæœ¬ï¼Œè®©æ›´å¤šçš„å¼€å‘è€…å‚ä¸åˆ°Text-to-SQLçš„å‡†ç¡®åº¦æå‡å·¥ä½œå½“ä¸­ï¼Œæœ€ç»ˆå®ç°åŸºäºæ•°æ®åº“çš„è‡ªåŠ¨é—®ç­”èƒ½åŠ›ï¼Œè®©ç”¨æˆ·å¯ä»¥é€šè¿‡è‡ªç„¶è¯­è¨€æè¿°å®Œæˆå¤æ‚æ•°æ®åº“çš„æŸ¥è¯¢æ“ä½œç­‰å·¥ä½œã€‚     
ç›®å‰æˆ‘ä»¬å·²ç»åŸºäºå¤šä¸ªå¤§æ¨¡å‹æ‰“é€šä»æ•°æ®å¤„ç†ã€æ¨¡å‹SFTè®­ç»ƒã€é¢„æµ‹è¾“å‡ºå’Œè¯„ä¼°çš„æ•´ä¸ªæµç¨‹ï¼Œ**ä»£ç åœ¨æœ¬é¡¹ç›®ä¸­å‡å¯ä»¥ç›´æ¥å¤ç”¨**ã€‚   
æˆªæ­¢20231010ï¼Œæˆ‘ä»¬åˆ©ç”¨æœ¬é¡¹ç›®åŸºäºå¼€æºçš„13Bå¤§å°çš„æ¨¡å‹å¾®è°ƒï¼Œç»“åˆæ›´å¤šç›¸å…³æ•°æ®ï¼Œåœ¨é›¶æ ·æœ¬æç¤ºä¸‹ï¼ŒåŸºäºSpiderçš„[test-suite](https://github.com/taoyds/test-suite-sql-eval)ä¸­çš„æ•°æ®åº“(å¤§å°1.27G)æ‰§è¡Œå‡†ç¡®ç‡å¯ä»¥è¾¾åˆ°**0.764**ï¼ŒåŸºäºSpider[å®˜æ–¹ç½‘ç«™](https://yale-lily.github.io/spider)æŒ‡å‘çš„æ•°æ®åº“(å¤§å°95M)çš„æ‰§è¡Œå‡†ç¡®ç‡ä¸º0.825ã€‚
éƒ¨åˆ†å®éªŒç»“æœå·²æ±‡æ€»åˆ°äº†æœ¬é¡¹ç›®çš„ç›¸å…³[æ–‡æ¡£](docs/eval_llm_result.md) ï¼Œå¯ä¾›å‚è€ƒã€‚

## äºŒã€Text-to-SQLå¾®è°ƒ

 æˆ‘ä»¬åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„SFTæ¥æå‡Text-to-SQLçš„æ•ˆæœã€‚

### 2.1ã€æ•°æ®é›†

æœ¬é¡¹ç›®æ¡ˆä¾‹æ•°æ®ä¸»è¦ä»¥**Spider**æ•°æ®é›†ä¸ºç¤ºä¾‹ ï¼š
- [Spider](https://yale-lily.github.io/spider): ä¸€ä¸ªè·¨åŸŸçš„å¤æ‚text2sqlæ•°æ®é›†ï¼ŒåŒ…å«äº†10,181æ¡è‡ªç„¶è¯­è¨€é—®å¥ã€åˆ†å¸ƒåœ¨200ä¸ªç‹¬ç«‹æ•°æ®åº“ä¸­çš„5,693æ¡SQLï¼Œå†…å®¹è¦†ç›–äº†138ä¸ªä¸åŒçš„é¢†åŸŸã€‚[ä¸‹è½½é“¾æ¥](https://drive.google.com/uc?export=download&id=1TqleXec_OykOYFREKKtschzY29dUcVAQ)

å…¶ä»–æ•°æ®é›†ï¼š  

- [WikiSQL:](https://github.com/salesforce/WikiSQL) ä¸€ä¸ªå¤§å‹çš„è¯­ä¹‰è§£ææ•°æ®é›†ï¼Œç”±80,654ä¸ªè‡ªç„¶è¯­å¥è¡¨è¿°å’Œ24,241å¼ è¡¨æ ¼çš„sqlæ ‡æ³¨æ„æˆã€‚WikiSQLä¸­æ¯ä¸€ä¸ªé—®å¥çš„æŸ¥è¯¢èŒƒå›´ä»…é™äºåŒä¸€å¼ è¡¨ï¼Œä¸åŒ…å«æ’åºã€åˆ†ç»„ã€å­æŸ¥è¯¢ç­‰å¤æ‚æ“ä½œã€‚
- [CHASE](https://xjtu-intsoft.github.io/chase/): ä¸€ä¸ªè·¨é¢†åŸŸå¤šè½®äº¤äº’text2sqlä¸­æ–‡æ•°æ®é›†ï¼ŒåŒ…å«5459ä¸ªå¤šè½®é—®é¢˜ç»„æˆçš„åˆ—è¡¨ï¼Œä¸€å…±17940ä¸ª<query, SQL>äºŒå…ƒç»„ï¼Œæ¶‰åŠ280ä¸ªä¸åŒé¢†åŸŸçš„æ•°æ®åº“ã€‚
- [BIRD-SQLï¼š](https://bird-bench.github.io/)æ•°æ®é›†æ˜¯ä¸€ä¸ªè‹±æ–‡çš„å¤§è§„æ¨¡è·¨é¢†åŸŸæ–‡æœ¬åˆ°SQLåŸºå‡†æµ‹è¯•ï¼Œç‰¹åˆ«å…³æ³¨å¤§å‹æ•°æ®åº“å†…å®¹ã€‚è¯¥æ•°æ®é›†åŒ…å«12,751å¯¹æ–‡æœ¬åˆ°SQLæ•°æ®å¯¹å’Œ95ä¸ªæ•°æ®åº“ï¼Œæ€»å¤§å°ä¸º33.4GBï¼Œè·¨è¶Š37ä¸ªèŒä¸šé¢†åŸŸã€‚BIRD-SQLæ•°æ®é›†é€šè¿‡æ¢ç´¢ä¸‰ä¸ªé¢å¤–çš„æŒ‘æˆ˜ï¼Œå³å¤„ç†å¤§è§„æ¨¡å’Œæ··ä¹±çš„æ•°æ®åº“å€¼ã€å¤–éƒ¨çŸ¥è¯†æ¨ç†å’Œä¼˜åŒ–SQLæ‰§è¡Œæ•ˆç‡ï¼Œç¼©å°äº†æ–‡æœ¬åˆ°SQLç ”ç©¶ä¸å®é™…åº”ç”¨ä¹‹é—´çš„å·®è·ã€‚
- [CoSQL:](https://yale-lily.github.io/cosql)æ˜¯ä¸€ä¸ªç”¨äºæ„å»ºè·¨åŸŸå¯¹è¯æ–‡æœ¬åˆ°sqlç³»ç»Ÿçš„è¯­æ–™åº“ã€‚å®ƒæ˜¯Spiderå’ŒSParCä»»åŠ¡çš„å¯¹è¯ç‰ˆæœ¬ã€‚CoSQLç”±30k+å›åˆå’Œ10k+å¸¦æ³¨é‡Šçš„SQLæŸ¥è¯¢ç»„æˆï¼Œè¿™äº›æŸ¥è¯¢æ¥è‡ªWizard-of-Ozçš„3kä¸ªå¯¹è¯é›†åˆï¼ŒæŸ¥è¯¢äº†è·¨è¶Š138ä¸ªé¢†åŸŸçš„200ä¸ªå¤æ‚æ•°æ®åº“ã€‚æ¯ä¸ªå¯¹è¯éƒ½æ¨¡æ‹Ÿäº†ä¸€ä¸ªçœŸå®çš„DBæŸ¥è¯¢åœºæ™¯ï¼Œå…¶ä¸­ä¸€ä¸ªå·¥ä½œäººå‘˜ä½œä¸ºç”¨æˆ·æ¢ç´¢æ•°æ®åº“ï¼Œä¸€ä¸ªSQLä¸“å®¶ä½¿ç”¨SQLæ£€ç´¢ç­”æ¡ˆï¼Œæ¾„æ¸…æ¨¡æ£±ä¸¤å¯çš„é—®é¢˜ï¼Œæˆ–è€…ä»¥å…¶ä»–æ–¹å¼é€šçŸ¥ã€‚
- æŒ‰ç…§[NSQL](https://github.com/NumbersStationAI/NSQL)çš„å¤„ç†æ¨¡æ¿ï¼Œå¯¹æ•°æ®é›†åšç®€å•å¤„ç†ï¼Œå…±å¾—åˆ°çº¦[20wæ¡è®­ç»ƒæ•°æ®](https://huggingface.co/datasets/Healthy13/Text2SQL/tree/main)



### 2.2ã€åŸºåº§æ¨¡å‹

DB-GPT-HUBç›®å‰å·²ç»æ”¯æŒçš„baseæ¨¡å‹æœ‰ï¼š

  - [x] CodeLlama
  - [x] Baichuan2 
  - [x] LLaMa/LLaMa2
  - [x] Falcon
  - [x] Qwen
  - [x] XVERSE
  - [x] ChatGLM2
  - [x] ChatGLM3
  - [x] internlm
  - [x] Falcon
  - [x] sqlcoder-7b(mistral)
  - [x] sqlcoder2-15b(starcoder)



æ¨¡å‹å¯ä»¥åŸºäºquantization_bitä¸º4çš„é‡åŒ–å¾®è°ƒ(QLoRA)æ‰€éœ€çš„æœ€ä½ç¡¬ä»¶èµ„æº,å¯ä»¥å‚è€ƒå¦‚ä¸‹ï¼š

| æ¨¡å‹å‚æ•° | GPU RAM | CPU RAM | DISK   |
| -------- | ------- | ------- | ------ |
| 7b       | 6GB     | 3.6GB   | 36.4GB |
| 13b      | 13.4GB  | 5.9GB   | 60.2GB |

å…¶ä¸­ç›¸å…³å‚æ•°å‡è®¾ç½®çš„ä¸ºæœ€å°ï¼Œbatch_sizeä¸º1ï¼Œmax_lengthä¸º512ã€‚æ ¹æ®ç»éªŒï¼Œå¦‚æœè®¡ç®—èµ„æºè¶³å¤Ÿï¼Œä¸ºäº†æ•ˆæœæ›´å¥½ï¼Œå»ºè®®ç›¸å…³é•¿åº¦å€¼è®¾ç½®ä¸º1024æˆ–è€…2048ã€‚  

## ä¸‰ã€ä½¿ç”¨æ–¹æ³•

### 3.1ã€ç¯å¢ƒå‡†å¤‡

```
git clone https://github.com/eosphoros-ai/DB-GPT-Hub.git
cd DB-GPT-Hub
conda create -n dbgpt_hub python=3.10 
conda activate dbgpt_hub
pip install poetry
poetry install
```

### 3.2ã€æ•°æ®å‡†å¤‡

DB-GPT-Hubä½¿ç”¨çš„æ˜¯ä¿¡æ¯åŒ¹é…ç”Ÿæˆæ³•è¿›è¡Œæ•°æ®å‡†å¤‡ï¼Œå³ç»“åˆè¡¨ä¿¡æ¯çš„ SQL + Repository ç”Ÿæˆæ–¹å¼ï¼Œè¿™ç§æ–¹å¼ç»“åˆäº†æ•°æ®è¡¨ä¿¡æ¯ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°ç†è§£æ•°æ®è¡¨çš„ç»“æ„å’Œå…³ç³»ï¼Œé€‚ç”¨äºç”Ÿæˆç¬¦åˆéœ€æ±‚çš„ SQL è¯­å¥ã€‚ 
ä»[spideræ•°æ®é›†é“¾æ¥](https://drive.google.com/uc?export=download&id=1TqleXec_OykOYFREKKtschzY29dUcVAQ) ä¸‹è½½spideræ•°æ®é›†ï¼Œé»˜è®¤å°†æ•°æ®ä¸‹è½½è§£å‹åï¼Œæ”¾åœ¨ç›®å½•dbgpt_hub_sql/dataä¸‹é¢ï¼Œå³è·¯å¾„ä¸º`dbgpt_hub_sql/data/spider`ã€‚ 

æ•°æ®é¢„å¤„ç†éƒ¨åˆ†ï¼Œ**åªéœ€è¿è¡Œå¦‚ä¸‹è„šæœ¬**å³å¯ï¼š
```bash
## ç”Ÿæˆtrainæ•°æ® å’Œdev(eval)æ•°æ®,
poetry run sh dbgpt_hub_sql/scripts/gen_train_eval_data.sh
```
åœ¨`dbgpt_hub_sql/data/`ç›®å½•ä½ ä¼šå¾—åˆ°æ–°ç”Ÿæˆçš„è®­ç»ƒæ–‡ä»¶example_text2sql_train.json å’Œæµ‹è¯•æ–‡ä»¶example_text2sql_dev.json ï¼Œæ•°æ®é‡åˆ†åˆ«ä¸º8659å’Œ1034æ¡ã€‚ å¯¹äºåé¢å¾®è°ƒæ—¶çš„æ•°æ®ä½¿ç”¨åœ¨dbgpt_hub_sql/data/dataset_info.jsonä¸­å°†å‚æ•°`file_name`å€¼ç»™ä¸ºè®­ç»ƒé›†çš„æ–‡ä»¶åï¼Œå¦‚example_text2sql_train.jsonã€‚

ç”Ÿæˆçš„jsonä¸­çš„æ•°æ®å½¢å¦‚ï¼š  
```
    {
        "db_id": "department_management",
        "instruction": "I want you to act as a SQL terminal in front of an example database, you need only to return the sql command to me.Below is an instruction that describes a task, Write a response that appropriately completes the request.\n\"\n##Instruction:\ndepartment_management contains tables such as department, head, management. Table department has columns such as Department_ID, Name, Creation, Ranking, Budget_in_Billions, Num_Employees. Department_ID is the primary key.\nTable head has columns such as head_ID, name, born_state, age. head_ID is the primary key.\nTable management has columns such as department_ID, head_ID, temporary_acting. department_ID is the primary key.\nThe head_ID of management is the foreign key of head_ID of head.\nThe department_ID of management is the foreign key of Department_ID of department.\n\n",
        "input": "###Input:\nHow many heads of the departments are older than 56 ?\n\n###Response:",
        "output": "SELECT count(*) FROM head WHERE age  >  56",
        "history": []
    }, 
```     
é¡¹ç›®çš„æ•°æ®å¤„ç†ä»£ç ä¸­å·²ç»åµŒå¥—äº†`chase` ã€`cosql`ã€`sparc`çš„æ•°æ®å¤„ç†ï¼Œå¯ä»¥æ ¹æ®ä¸Šé¢é“¾æ¥å°†æ•°æ®é›†ä¸‹è½½åˆ°dataè·¯å¾„åï¼Œåœ¨`dbgpt_hub_sql/configs/config.py`ä¸­å°† `SQL_DATA_INFO`ä¸­å¯¹åº”çš„ä»£ç æ³¨é‡Šæ¾å¼€å³å¯ã€‚  

### 3.2 å¿«é€Ÿå¼€å§‹

é¦–å…ˆï¼Œç”¨å¦‚ä¸‹å‘½ä»¤å®‰è£…`dbgpt-hub`ï¼š

`pip install dbgpt-hub`

ç„¶åï¼ŒæŒ‡å®šå‚æ•°å¹¶ç”¨å‡ è¡Œä»£ç å®Œæˆæ•´ä¸ªText2SQL fine-tuneæµç¨‹ï¼š
```python
from dbgpt_hub_sql.data_process import preprocess_sft_data
from dbgpt_hub_sql.train import start_sft
from dbgpt_hub_sql.predict import start_predict
from dbgpt_hub_sql.eval import start_evaluate

# é…ç½®è®­ç»ƒå’ŒéªŒè¯é›†è·¯å¾„å’Œå‚æ•°
data_folder = "dbgpt_hub_sql/data"
data_info = [
        {
            "data_source": "spider",
            "train_file": ["train_spider.json", "train_others.json"],
            "dev_file": ["dev.json"],
            "tables_file": "tables.json",
            "db_id_name": "db_id",
            "is_multiple_turn": False,
            "train_output": "spider_train.json",
            "dev_output": "spider_dev.json",
        }
]

# é…ç½®fine-tuneå‚æ•°
train_args = {
            "model_name_or_path": "codellama/CodeLlama-13b-Instruct-hf",
            "do_train": True,
            "dataset": "example_text2sql_train",
            "max_source_length": 2048,
            "max_target_length": 512,
            "finetuning_type": "lora",
            "lora_target": "q_proj,v_proj",
            "template": "llama2",
            "lora_rank": 64,
            "lora_alpha": 32,
            "output_dir": "dbgpt_hub_sql/output/adapter/CodeLlama-13b-sql-lora",
            "overwrite_cache": True,
            "overwrite_output_dir": True,
            "per_device_train_batch_size": 1,
            "gradient_accumulation_steps": 16,
            "lr_scheduler_type": "cosine_with_restarts",
            "logging_steps": 50,
            "save_steps": 2000,
            "learning_rate": 2e-4,
            "num_train_epochs": 8,
            "plot_loss": True,
            "bf16": True,
}

# é…ç½®é¢„æµ‹å‚æ•°
predict_args = {
            "model_name_or_path": "codellama/CodeLlama-13b-Instruct-hf",
            "template": "llama2",
            "finetuning_type": "lora",
            "checkpoint_dir": "dbgpt_hub_sql/output/adapter/CodeLlama-13b-sql-lora",
            "predict_file_path": "dbgpt_hub_sql/data/eval_data/dev_sql.json",
            "predict_out_dir": "dbgpt_hub_sql/output/",
            "predicted_out_filename": "pred_sql.sql",
}

# é…ç½®è¯„ä¼°å‚æ•°
evaluate_args =  {
            "input": "./dbgpt_hub_sql/output/pred/pred_sql_dev_skeleton.sql",
            "gold": "./dbgpt_hub_sql/data/eval_data/gold.txt",
            "gold_natsql": "./dbgpt_hub_sql/data/eval_data/gold_natsql2sql.txt",
            "db": "./dbgpt_hub_sql/data/spider/database",
            "table": "./dbgpt_hub_sql/data/eval_data/tables.json",
            "table_natsql": "./dbgpt_hub_sql/data/eval_data/tables_for_natsql2sql.json",
            "etype": "exec",
            "plug_value": True,
            "keep_distict": False,
            "progress_bar_for_each_datapoint": False,
            "natsql": False,
}

# æ‰§è¡Œæ•´ä¸ªFine-tuneæµç¨‹
preprocess_sft_data(
      data_folder = data_folder,
      data_info = data_info
)

start_sft(train_args)
start_predict(predict_args)
start_evaluate(evaluate_args)
```

### 3.3ã€æ¨¡å‹å¾®è°ƒ

æœ¬é¡¹ç›®å¾®è°ƒä¸ä»…èƒ½æ”¯æŒQLoRAå’ŒLoRAæ³•ï¼Œè¿˜æ”¯æŒdeepseedã€‚ å¯ä»¥è¿è¡Œä»¥ä¸‹å‘½ä»¤æ¥å¾®è°ƒæ¨¡å‹ï¼Œé»˜è®¤å¸¦ç€å‚æ•°`--quantization_bit `ä¸ºQLoRAçš„å¾®è°ƒæ–¹å¼ï¼Œå¦‚æœæƒ³è¦è½¬æ¢ä¸ºloraçš„å¾®è°ƒï¼Œåªéœ€åœ¨è„šæœ¬ä¸­å»æ‰quantization_bitå‚æ•°å³å¯ã€‚
é»˜è®¤QLoRAå¾®è°ƒï¼Œè¿è¡Œå‘½ä»¤ï¼š

```bash
poetry run sh dbgpt_hub_sql/scripts/train_sft.sh
```
å¾®è°ƒåçš„æ¨¡å‹æƒé‡ä¼šé»˜è®¤ä¿å­˜åˆ°adapteræ–‡ä»¶å¤¹ä¸‹é¢ï¼Œå³dbgpt_hub_sql/output/adapterç›®å½•ä¸­ã€‚  
**å¦‚æœä½¿ç”¨å¤šå¡è®­ç»ƒï¼Œæƒ³è¦ç”¨deepseed** ï¼Œåˆ™å°†train_sft.shä¸­é»˜è®¤çš„å†…å®¹è¿›è¡Œæ›´æ”¹ï¼Œ
è°ƒæ•´ä¸ºï¼š

```
CUDA_VISIBLE_DEVICES=0 python dbgpt_hub_sql/train/sft_train.py \
    --quantization_bit 4 \
    ...
```    
æ›´æ”¹ä¸ºï¼š 
```
deepspeed --num_gpus 2  dbgpt_hub_sql/train/sft_train.py \
    --deepspeed dbgpt_hub_sql/configs/ds_config.json \
    --quantization_bit 4 \
    ...
```   
å¦‚æœéœ€è¦æŒ‡å®šå¯¹åº”çš„æ˜¾å¡idè€Œä¸æ˜¯é»˜è®¤çš„å‰ä¸¤ä¸ªå¦‚3,4ï¼Œå¯ä»¥å¦‚ä¸‹
```
deepspeed --include localhost:3,4  dbgpt_hub_sql/train/sft_train.py \
    --deepspeed dbgpt_hub_sql/configs/ds_config.json \
    --quantization_bit 4 \
    ...
```    

å…¶ä»–çœç•¥(...)çš„éƒ¨åˆ†å‡ä¿æŒä¸€è‡´å³å¯ã€‚ å¦‚æœæƒ³è¦æ›´æ”¹é»˜è®¤çš„deepseedé…ç½®ï¼Œè¿›å…¥ `dbgpt_hub_sql/configs` ç›®å½•ï¼Œåœ¨ds_config.json æ›´æ”¹å³å¯ï¼Œé»˜è®¤ä¸ºstage2çš„ç­–ç•¥ã€‚

è„šæœ¬ä¸­å¾®è°ƒæ—¶ä¸åŒæ¨¡å‹å¯¹åº”çš„å…³é”®å‚æ•°lora_target å’Œ templateï¼Œå¦‚ä¸‹è¡¨ï¼š

| æ¨¡å‹å                                                   | lora_target     | template  |
| -------------------------------------------------------- | --------------- | --------- |
| [LLaMA-2](https://huggingface.co/meta-llama)             | q_proj,v_proj   | llama2    |
| [CodeLlama-2](https://huggingface.co/codellama/)         | q_proj,v_proj   | llama2    |
| [Baichuan2](https://github.com/baichuan-inc/Baichuan2)   | W_pack          | baichuan2 |
| [Qwen](https://github.com/QwenLM/Qwen-7B)                | c_attn          | chatml    |
| [sqlcoder-7b](https://huggingface.co/defog/sqlcoder-7b)  | q_proj,v_proj   | mistral   |
| [sqlcoder2-15b](https://huggingface.co/defog/sqlcoder2)  | c_attn          | default   |
| [InternLM](https://github.com/InternLM/InternLM)         | q_proj,v_proj   | intern    |
| [XVERSE](https://github.com/xverse-ai/XVERSE-13B)        | q_proj,v_proj   | xverse    |
| [ChatGLM2](https://github.com/THUDM/ChatGLM2-6B)         | query_key_value | chatglm2  |
| [LLaMA](https://github.com/facebookresearch/llama)       | q_proj,v_proj   | -         |
| [BLOOM](https://huggingface.co/bigscience/bloom)         | query_key_value | -         |
| [BLOOMZ](https://huggingface.co/bigscience/bloomz)       | query_key_value | -         |
| [Baichuan](https://github.com/baichuan-inc/baichuan-13B) | W_pack          | baichuan  |
| [Falcon](https://huggingface.co/tiiuae/falcon-7b)        | query_key_value | -         |


`train_sft.sh`ä¸­å…¶ä»–å…³é”®å‚æ•°å«ä¹‰ï¼š
> quantization_bitï¼šæ˜¯å¦é‡åŒ–ï¼Œå–å€¼ä¸º[4æˆ–è€…8]   
> model_name_or_pathï¼š  LLMæ¨¡å‹çš„è·¯å¾„   
> datasetï¼š å–å€¼ä¸ºè®­ç»ƒæ•°æ®é›†çš„é…ç½®åå­—ï¼Œå¯¹åº”åœ¨dbgpt_hub_sql/data/dataset_info.json ä¸­å¤–å±‚keyå€¼ï¼Œå¦‚example_text2sqlã€‚   
> max_source_lengthï¼š è¾“å…¥æ¨¡å‹çš„æ–‡æœ¬é•¿åº¦ï¼Œå¦‚æœè®¡ç®—èµ„æºæ”¯æŒï¼Œå¯ä»¥å°½èƒ½è®¾å¤§ï¼Œå¦‚1024æˆ–è€…2048ã€‚  
> max_target_lengthï¼š è¾“å‡ºæ¨¡å‹çš„sqlå†…å®¹é•¿åº¦ï¼Œè®¾ç½®ä¸º512ä¸€èˆ¬è¶³å¤Ÿã€‚   
> output_dir ï¼š SFTå¾®è°ƒæ—¶Peftæ¨¡å—è¾“å‡ºçš„è·¯å¾„ï¼Œé»˜è®¤è®¾ç½®åœ¨dbgpt_hub_sql/output/adapter/è·¯å¾„ä¸‹ ã€‚  
> per_device_train_batch_size ï¼š batchçš„å¤§å°ï¼Œå¦‚æœè®¡ç®—èµ„æºæ”¯æŒï¼Œå¯ä»¥è®¾ç½®ä¸ºæ›´å¤§ï¼Œé»˜è®¤ä¸º1ã€‚   
> gradient_accumulation_steps ï¼š æ¢¯åº¦æ›´æ–°çš„ç´¯è®¡stepså€¼ 
> save_steps ï¼š æ¨¡å‹ä¿å­˜çš„ckptçš„stepså¤§å°å€¼ï¼Œé»˜è®¤å¯ä»¥è®¾ç½®ä¸º100ã€‚  
> num_train_epochs ï¼š è®­ç»ƒæ•°æ®çš„epochæ•°   




### 3.4ã€æ¨¡å‹é¢„æµ‹
é¡¹ç›®ç›®å½•ä¸‹`./dbgpt_hub_sql/`ä¸‹çš„`output/pred/`ï¼Œæ­¤æ–‡ä»¶è·¯å¾„ä¸ºå…³äºæ¨¡å‹é¢„æµ‹ç»“æœé»˜è®¤è¾“å‡ºçš„ä½ç½®(å¦‚æœæ²¡æœ‰åˆ™å»ºä¸Š)ã€‚   
é¢„æµ‹è¿è¡Œå‘½ä»¤ï¼š
```bash
poetry run sh ./dbgpt_hub_sql/scripts/predict_sft.sh
```   
è„šæœ¬ä¸­é»˜è®¤å¸¦ç€å‚æ•°`--quantization_bit `ä¸ºQLoRAçš„é¢„æµ‹ï¼Œå»æ‰å³ä¸ºLoRAçš„é¢„æµ‹æ–¹å¼ã€‚  
å…¶ä¸­å‚æ•°`predicted_input_filename`  ä¸ºè¦é¢„æµ‹çš„æ•°æ®é›†æ–‡ä»¶ï¼Œ `--predicted_out_filename` çš„å€¼ä¸ºæ¨¡å‹é¢„æµ‹çš„ç»“æœæ–‡ä»¶åã€‚é»˜è®¤ç»“æœä¿å­˜åœ¨`dbgpt_hub_sql/output/pred`ç›®å½•ã€‚


### 3.5ã€æ¨¡å‹æƒé‡
å¯ä»¥ä»HuggingfaceæŸ¥çœ‹æˆ‘ä»¬ç¤¾åŒºä¸Šä¼ çš„ç¬¬äºŒç‰ˆPeftæ¨¡å—æƒé‡[huggingfaceåœ°å€](https://huggingface.co/Wangzaistone123/CodeLlama-13b-sql-lora) (202310) ,åœ¨spiderè¯„ä¼°é›†ä¸Šçš„æ‰§è¡Œå‡†ç¡®ç‡è¾¾åˆ°0.789ã€‚    

#### 3.5.1 æ¨¡å‹å’Œå¾®è°ƒæƒé‡åˆå¹¶
å¦‚æœä½ éœ€è¦å°†è®­ç»ƒçš„åŸºç¡€æ¨¡å‹å’Œå¾®è°ƒçš„Peftæ¨¡å—çš„æƒé‡åˆå¹¶ï¼Œå¯¼å‡ºä¸€ä¸ªå®Œæ•´çš„æ¨¡å‹ã€‚åˆ™è¿è¡Œå¦‚ä¸‹æ¨¡å‹å¯¼å‡ºè„šæœ¬ï¼š  
```bash
poetry run sh ./dbgpt_hub_sql/scripts/export_merge.sh
```
æ³¨æ„å°†è„šæœ¬ä¸­çš„ç›¸å…³å‚æ•°è·¯å¾„å€¼æ›¿æ¢ä¸ºä½ é¡¹ç›®æ‰€å¯¹åº”çš„è·¯å¾„ã€‚      


### 3.6ã€æ¨¡å‹è¯„ä¼°
å¯¹äºæ¨¡å‹åœ¨æ•°æ®é›†ä¸Šçš„æ•ˆæœè¯„ä¼°,é»˜è®¤ä¸ºåœ¨`spider`æ•°æ®é›†ä¸Šã€‚
è¿è¡Œä»¥ä¸‹å‘½ä»¤æ¥ï¼š

```bash
poetry run python dbgpt_hub_sql/eval/evaluation.py --plug_value --input  Your_model_pred_file
```
ä½ å¯ä»¥åœ¨[è¿™é‡Œ](docs/eval_llm_result.md)æ‰¾åˆ°æˆ‘ä»¬æœ€æ–°çš„è¯„ä¼°å’Œå®éªŒç»“æœã€‚
**æ³¨æ„**ï¼š é»˜è®¤çš„ä»£ç ä¸­æŒ‡å‘çš„æ•°æ®åº“ä¸ºä»[Spiderå®˜æ–¹ç½‘ç«™](https://yale-lily.github.io/spider)ä¸‹è½½çš„å¤§å°ä¸º95Mçš„databaseï¼Œå¦‚æœä½ éœ€è¦ä½¿ç”¨åŸºäºSpiderçš„[test-suite](https://github.com/taoyds/test-suite-sql-eval)ä¸­çš„æ•°æ®åº“(å¤§å°1.27G)ï¼Œè¯·å…ˆä¸‹è½½é“¾æ¥ä¸­çš„æ•°æ®åº“åˆ°è‡ªå®šä¹‰ç›®å½•ï¼Œå¹¶åœ¨ä¸Šè¿°è¯„ä¼°å‘½ä»¤ä¸­å¢åŠ å‚æ•°å’Œå€¼ï¼Œå½¢å¦‚`--db Your_download_db_path`ã€‚

## å››ã€å‘å±•è·¯çº¿    
æ•´ä¸ªè¿‡ç¨‹æˆ‘ä»¬ä¼šåˆ†ä¸ºä¸‰ä¸ªé˜¶æ®µï¼š

* é˜¶æ®µä¸€:
  * æ­å»ºåŸºæœ¬æ¡†æ¶ï¼ŒåŸºäºæ•°ä¸ªå¤§æ¨¡å‹æ‰“é€šä»æ•°æ®å¤„ç†ã€æ¨¡å‹SFTè®­ç»ƒã€é¢„æµ‹è¾“å‡ºå’Œè¯„ä¼°çš„æ•´ä¸ªæµç¨‹ï¼Œæˆªæ­¢`20230804`æˆ‘ä»¬å·²ç»æ•´ä¸ªæ‰“é€šã€‚
  æˆ‘ä»¬ç°åœ¨æ”¯æŒ 
  - [x] CodeLlama
  - [x] Baichuan2 
  - [x] LLaMa/LLaMa2
  - [x] Falcon
  - [x] Qwen
  - [x] XVERSE
  - [x] ChatGLM2
  - [x] ChatGLM3
  - [x] internlm    
  - [x] sqlcoder-7b(mistral)
  - [x] sqlcoder2-15b(starcoder)
  
* é˜¶æ®µäºŒ:
  - [x]  ä¼˜åŒ–æ¨¡å‹æ•ˆæœï¼Œæ”¯æŒæ›´å¤šä¸åŒæ¨¡å‹è¿›è¡Œä¸åŒæ–¹å¼çš„å¾®è°ƒã€‚æˆªæ­¢`20231010`ï¼Œæˆ‘ä»¬å·²ç»å®Œæˆå¯¹é¡¹ç›®ä»£ç çš„é‡æ„ï¼Œæ”¯æŒæ›´å¤šçš„æ¨¡å‹ã€‚
  - [x] å¯¹`prompt`ä¼˜åŒ–
  - [x] æ”¾å‡ºè¯„ä¼°æ•ˆæœï¼Œå’Œä¼˜åŒ–åçš„è¿˜ä¸é”™çš„æ¨¡å‹ï¼Œå¹¶ä¸”ç»™å‡ºå¤ç°æ•™ç¨‹(è§æˆ‘ä»¬å¾®ä¿¡å…¬ä¼—å·EosphorosAI)    
      
* é˜¶æ®µä¸‰ï¼š
  - [ ] æ¨ç†é€Ÿåº¦ä¼˜åŒ–æå‡
  - [ ] ä¸šåŠ¡åœºæ™¯å’Œä¸­æ–‡æ•ˆæœé’ˆå¯¹æ€§ä¼˜åŒ–æå‡
  - [ ] åŸºäºæ›´å¤šè®ºæ–‡è¿›è¡Œä¼˜åŒ–ï¼Œå¦‚`RESDSQL`ç­‰ï¼Œç»“åˆæˆ‘ä»¬ç¤¾åŒºçš„å…„å¼Ÿé¡¹ç›®[Awesome-Text2SQL](https://github.com/eosphoros-ai/Awesome-Text2SQL)è¿›è¡Œæ›´å¤šçš„ä¼˜åŒ–ï¼›  

  **å¦‚æœä½ è§‰å¾—æˆ‘ä»¬çš„å·¥ä½œå¯¹ä½ æœ‰é‚£ä¹ˆç‚¹å¸®åŠ©ï¼Œè¿˜è¯·ç»™æˆ‘ä»¬ä¸ªstaré¼“åŠ±ä¸‹ï¼Œæˆ‘ä»¬ä¼šæœ‰æ›´å¤šåŠ¨åŠ›å»æ”¾å‡ºæ›´å¤šç›¸å…³å·¥ä½œã€‚**

## äº”ã€è´¡çŒ®

æ¬¢è¿æ›´å¤šå°ä¼™ä¼´åœ¨æ•°æ®é›†ã€æ¨¡å‹å¾®è°ƒã€æ•ˆæœè¯„æµ‹ã€è®ºæ–‡æ¨èä¸å¤ç°ç­‰æ–¹é¢å‚ä¸å’Œåé¦ˆï¼Œå¦‚æissuesæˆ–è€…pråé¦ˆï¼Œæˆ‘ä»¬ä¼šç§¯æç»™å‡ºå›åº”ã€‚æäº¤ä»£ç å‰è¯·å…ˆå°†ä»£ç æŒ‰blackæ ¼å¼åŒ–ï¼Œè¿è¡Œä¸‹`black .`ã€‚

## å…­ã€æ„Ÿè°¢

æˆ‘ä»¬çš„å·¥ä½œä¸»è¦æ˜¯åœ¨ä¼—å¤šå¼€æºå·¥ä½œçš„åŸºç¡€ä¸Šå¼€å±•çš„ï¼Œéå¸¸æ„Ÿè°¢ä»¥ä¸‹å¼€æºé¡¹ç›®ã€‚

* [Spider](https://github.com/ElementAI/spider)
* [CoSQL](https://yale-lily.github.io/cosql)
* [Chase](https://xjtu-intsoft.github.io/chase/)
* [BIRD-SQL](https://bird-bench.github.io/)
* [LLaMA](https://github.com/facebookresearch/llama/tree/main)
* [BLOOM](https://huggingface.co/spaces/bigscience/license)
* [Falcon](https://github.com/hiyouga/LLaMA-Efficient-Tuning/blob/main/LICENSE)
* [ChatGLM](https://github.com/search?q=ChatGLM&type=repositories)
* [WizardLM](https://github.com/nlpxucan/WizardLM)
* [text-to-sql-wizardcoder](https://github.com/cuplv/text-to-sql-wizardcoder)
* [test-suite-sql-eval](https://github.com/taoyds/test-suite-sql-eval)
* [LLaMa-Efficient-Tuning](https://github.com/hiyouga/LLaMA-Efficient-Tuning) 

éå¸¸æ„Ÿè°¢æ‰€æœ‰çš„contributors! 
 **20231104** ,å°¤å…¶æ„Ÿè°¢ @[JBoRu](https://github.com/JBoRu) æçš„[issue](https://github.com/eosphoros-ai/DB-GPT-Hub/issues/119)ï¼Œ æŒ‡å‡ºæˆ‘ä»¬çš„ä¹‹å‰æŒ‰ç…§å®˜æ–¹ç½‘ç«™çš„95Mçš„æ•°æ®åº“å»è¯„ä¼°çš„æ–¹å¼çš„ä¸è¶³ï¼Œå¦‚è®ºæ–‡ã€ŠSQL-PALM: IMPROVED LARGE LANGUAGE MODEL ADAPTATION FOR TEXT-TO-SQLã€‹ æŒ‡å‡ºçš„ "We consider two commonly-used evaluation metrics: execution accuracy (EX) and test-suite accuracy (TS) [32]. EX measures whether SQL execution outcome matches ground truth (GT), whereas TS measures whether the SQL passes all EX evaluation for multiple tests, generated by database-augmentation. Since EX contains false positives, we consider TS as a more reliable evaluation metric" ã€‚

## ä¸ƒã€å¼•ç”¨
å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨çš„ç§‘ç ”é¡¹ç›®æˆ–è€…å®é™…ç”Ÿäº§é¡¹ç›®æœ‰å¸®åŠ©ï¼Œè¯·è€ƒè™‘åœ¨æ‚¨çš„å‚è€ƒæ–‡çŒ®é‡Œå¼•ç”¨`DB-GPT-Hub`:

```bibtex
@software{db-gpt-hub,
    author = {DB-GPT-Hub Team},
    title = {{DB-GPT-Hub}},
    url = {https://github.com/eosphoros-ai/DB-GPT-Hub},
    year = {2023}
}
```

## å…«ã€Licence

The MIT License (MIT)

## ä¹ã€æˆ‘ä»¬çš„è”ç³»æ–¹å¼
æˆ‘ä»¬æ˜¯ä¸€ä¸ªç¤¾åŒºä¸€èµ·åˆä½œï¼Œå¦‚æœä½ å¯¹æˆ‘ä»¬çš„ç¤¾åŒºå·¥ä½œæœ‰ä»»ä½•å»ºè®®ï¼Œéšæ—¶å¯ä»¥è”ç³»æˆ‘ä»¬ã€‚å¦‚æœä½ å¯¹DB-GPT-Hubå­é¡¹ç›®çš„æ·±å…¥å®éªŒå’Œä¼˜åŒ–æ„Ÿå…´è¶£ï¼Œå¯ä»¥è”ç³»å¾®ä¿¡ç¾¤é‡Œçš„wangzaiï¼Œæˆ‘ä»¬æ¬¢è¿å¤§å®¶å…±åŒåŠªåŠ›ï¼Œä½¿å®ƒå˜å¾—æ›´å¥½ã€‚
[![](https://dcbadge.vercel.app/api/server/7uQnPuveTY?compact=true&style=flat)](https://discord.gg/7uQnPuveTY)


[![Star History Chart](https://api.star-history.com/svg?repos=eosphoros-ai/DB-GPT-Hub&type=Date)](https://star-history.com/#eosphoros-ai/DB-GPT-Hub)
