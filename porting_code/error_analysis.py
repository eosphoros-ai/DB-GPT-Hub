# USAGE
"""
python error_analysis.py \
  --db_dir=/usr/local/google/home/gkakkar/dev/dev_databases \
  --dev_json_path=/usr/local/google/home/gkakkar/dev/dev.json \
  --generated_sqls_file=generated_sqls.sql \
  --col_selection_schema_file=col_selection_schema.csv \
  --error_analysis_file=error_analysis.csv
"""

import argparse
from concurrent.futures import ThreadPoolExecutor
import json, re
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.pydantic_v1 import BaseModel, Field
from nl2sql_eval import call_vertex_llm
from nl2sql_eval.chess_utils.execution import compare_sqls
import pandas as pd
from pathlib import Path  

debug_prompt = """You are an AI SQL expert. Compare the incorrect SQL query with the correct one, considering the database schema, and explain the errors.  Provide a structured analysis of the errors in JSON format.

Database Schema: {}

User Question: {}

User Hint: {}

Here's the incorrect SQL query generated by a model:
{}

Here's the correct SQL query:
{}

Provide a structured analysis of the errors in a valid JSON format as follows. 
Ensure there are no double quotes in the description. Convert them to single quotes. I will give you 1 million dollars if you follow all the instructions and generate the correct query.:

```json
{{
    "error_category": "[Select one from: Join Error, Aggregation Error, Filtering Error, Column/Table Reference Error, Syntax Error, Logic Error, Distinct Error, Other]",
    "error_description": "[Explain the specific error in detail, referencing the queries and prompt. Ensure there are no double quotes in the description. Convert them to single quotes."]",
    "potential_causes": "[List possible reasons why the NL2SQL model might have made this error. Ensure there are no double quotes in the description. Convert them to single quotes.]",
    "suggestions": "[Offer concrete suggestions for improving the NL2SQL model or prompt. Ensure there are no double quotes in the description. Convert them to single quotes.]"
}}

"""


def summarize_error_using_llm(
    original_prompt, question, hint, generated_query, correct_query
):
  llm_prompt = debug_prompt.format(
      original_prompt, question, hint, generated_query, correct_query
  )
  try:
    response = call_vertex_llm(llm_prompt)
  except Exception as e:
    print(e)
    return str(e)
  return response


def parallelize_error_summary(df, func, num_workers=4):
  """Applies a function to a DataFrame in parallel using ThreadPoolExecutor."""
  with ThreadPoolExecutor(max_workers=num_workers) as executor:
    results = list(
        executor.map(
            func,
            df['schema'],
            df['question'],
            df['evidence'],
            df['generated_sql'],
            df['SQL'],
        )
    )
  return results


def clean_data(text):
  start = text.find('{')
  end = text.find('}') + 1
  try:
    text = str(
        json.loads(
            re.sub(
                r'`([^`]*)`',
                lambda m: m.group(0).replace('"', '').replace('\\', ''),
                text[start:end].replace('\n', ''),
            ).replace('`', '')
        )
    )
  except Exception as e:
    print(e)
    return text
  return text


class ErrorSummary(BaseModel):
  error_category: str = Field(description='error category')
  error_description: str = Field(description='error description')
  potential_causes: str = Field(
      description=(
          'List possible reasons why the NL2SQL model might have made this'
          ' error'
      )
  )
  suggestions: str = Field(
      description=(
          'Offer concrete suggestions for improving the NL2SQL model or prompt'
      )
  )


def compare_sqls_wrapper(db_dir, db_id, fixed_sql, correct_query):
  """Wraps compare_sqls to work with DataFrame.apply"""
  db_path = Path(db_dir) / f'{db_id}' / f'{db_id}.sqlite'
  # print("db_path", db_path)
  return compare_sqls(db_path, fixed_sql, correct_query)


def expand_error_summary(error_summary):
  try:
    # error_summary = clean_data(error_summary)
    parser = JsonOutputParser(pydantic_object=ErrorSummary)
    error_summary = parser.parse(error_summary)
    return error_summary
  except Exception as e:
    print(e)
    return {
        'error_category': '',
        'error_description': '',
        'potential_causes': '',
        'suggestions': '',
    }


def main(args):
  db_dir = args.db_dir
  error_analysis_file = args.error_analysis_file
  generated_sqls_file = args.generated_sqls_file
  dev_json_path = args.dev_json_path
  col_selection_schema_file = args.col_selection_schema_file
  num_workers = args.num_workers

  generated_sqls = open(f'{generated_sqls_file}').readlines()
  total_queries = pd.read_json(f'{dev_json_path}')

  total_queries['generated_sql'] = generated_sqls

  col_sel = pd.read_csv(f'{col_selection_schema_file}')
  total_queries = total_queries.merge(col_sel, on='question_id', how='left')
  total_queries[['exec_res', 'exec_err']] = total_queries.apply(
      lambda x: compare_sqls_wrapper(
          db_dir, x['db_id'], x['generated_sql'], x['SQL']
      ),
      axis=1,
  ).apply(pd.Series)

  wrong_queries = total_queries[total_queries['exec_res'] == 0]
  print('Acc: ', (len(total_queries) - len(wrong_queries)) / len(total_queries))

  wrong_queries['error_summary'] = parallelize_error_summary(
      wrong_queries, summarize_error_using_llm, num_workers=num_workers
  )
  wrong_queries[
      ['error_category', 'error_description', 'potential_causes', 'suggestions']
  ] = (
      wrong_queries['error_summary']
      .apply(expand_error_summary)
      .apply(pd.Series)
  )
  wrong_queries.to_csv(f'{error_analysis_file}')


if __name__ == '__main__':
  parser = argparse.ArgumentParser()
  parser.add_argument(
      '--db_dir',
      type=str,
      required=True,
      help='Path to the databases',
  )
  parser.add_argument(
      '--dev_json_path',
      type=str,
      required=True,
      help='Path to the dev.json file',
  )
  parser.add_argument(
      '--generated_sqls_file',
      type=str,
      required=True,
      help='Path to file containing generated SQLs',
  )
  parser.add_argument(
      '--col_selection_schema_file',
      type=str,
      required=True,
      help='Path to the col_selection_schema.csv file',
  )
  parser.add_argument(
      '--error_analysis_file',
      type=str,
      default='error_analysis.csv',
      help='Filename for error analysis output',
  )
  parser.add_argument(
      '--num_workers',
      type=int,
      default=4,
      help='Number of workers for parallel processing',
  )
  args = parser.parse_args()
  main(args)

